Unter Skalierbarkeit versteht man unter anderem in der Elektronischen Datenverarbeitung die Fhigkeit eines Systems aus Hard- und Software, die Leistung durch das Hinzufgen von Ressourcen  z. B. weiterer Hardware  in einem definierten Bereich proportional (bzw. linear) zu steigern.
In der Betriebswirtschaftslehre dient der Begriff hingegen ganz allgemein zur Bezeichnung der Expansionsfhigkeit eines Geschftsmodells z. B. durch bertragung auf neue Mrkte oder Franchising.
Eine allgemein gltige Definition dieses Begriffs ist allerdings nicht trivial. Es ist erforderlich, fr den jeweiligen speziellen Fall, stets einen Bereich anzugeben. (z. B. muss ein System bei 100 gleichzeitigen Zugriffen nicht zwangslufig gleich gut skalieren wie bei 100.000 Zugriffen) Ressourcen knnen z. B. CPU, RAM, Festplatten oder Netzwerk-Bandbreite sein.
Die Skalierbarkeit eines Systems wird mit dem Skalierungsfaktor  auch SpeedUp genannt  angegeben.

== Vertikale vs. horizontale SkalierungBearbeiten ==
Man kann die Leistung eines Systems auf zwei verschiedene Arten steigern:

=== Vertikale Skalierung (scale up)Bearbeiten ===
Unter vertikaler Skalierung versteht man ein Steigern der Leistung durch das Hinzufgen von Ressourcen zu einem Knoten/Rechner des Systems. Beispiele dafr wren das Vergrern von Speicherplatz, das Hinzufgen einer CPU, oder das Einbauen einer leistungsstrkeren Grafikkarte.
Charakteristisch fr diese Art von Skalierung ist, dass ein System unabhngig von der Implementierung der Software schneller gemacht werden kann. Das heit, es muss keine Zeile Code gendert werden, um eine Leistungssteigerung durch vertikales Skalieren zu erfahren. Der groe Nachteil dabei ist jedoch, dass man frher oder spter auf ein Limit stt, bei dem man den Rechner nicht mehr aufrsten kann, wenn man bereits die beste Hardware verwendet, die zu diesem Zeitpunkt am Markt ist.

=== Horizontale Skalierung (scale out)Bearbeiten ===
Im Gegensatz zur vertikalen Skalierung sind der horizontalen Skalierung keine Grenzen (aus Sicht der Hardware) gesetzt. Horizontale Skalierung bedeutet die Steigerung der Leistung eines Systems durch das Hinzufgen zustzlicher Rechner/Knoten. Die Effizienz dieser Art der Skalierung ist jedoch stark von der Implementierung der Software abhngig, da nicht jede Software gleich gut parallelisierbar ist.

== Arten von SkalierbarkeitBearbeiten ==
Grundstzlich unterscheidet man vier Arten von Skalierbarkeit:

=== LastskalierbarkeitBearbeiten ===
Lastskalierbarkeit steht fr ein konstantes Systemverhalten ber grere Lastbereiche hinweg. Das bedeutet, dass ein System zum einen sowohl bei geringer, mittlerer, als auch bei hoher Last keine zu groe Verzgerung aufweist und die Anfragen rasch abgearbeitet werden knnen.

==== Beispiel MuseumsgarderobeBearbeiten ====
Bei einer Garderobe in einem Museum, bei welcher Besucher Jacken abgeben und wieder abholen, gilt das First-Come-First-Served-Prinzip. Dabei gibt es eine beschrnkte Anzahl an Kleiderhaken und eine grere Anzahl an Besuchern. Die Garderobe, an der sich die Besucher in einer Reihe anstellen, ist ein Karussell. Um einen freien Haken, bzw. seine Jacke zu finden, suchen die Besucher jeweils linear danach.
Unser Ziel ist es nun die Zeit, die ein Besucher tatschlich im Museum verbringen kann, zu maximieren.
Die Performance dieses Systems ist unter hoher Last dramatisch schlecht. Erstens wird das Suchen freier Haken immer aufwndiger, je weniger freie Haken zur Verfgung stehen. Zweitens ist unter hoher Auslastung (z. B. im Winter) ein Deadlock vorprogrammiert. Whrend am Morgen smtliche Besucher ihre Jacken abgeben, holen sie sich diese am Abend wieder alle ab. Ein Deadlock wird voraussichtlich mittags und am frhen Nachmittag auftreten, wenn keine freien Kleiderhaken mehr verfgbar sind und weitere Besucher am Ende der Schlange stehen um ihre Jacke abzuholen.
Personen, die ihre Jacke abholen mchten, knnten diesen Deadlock auflsen, indem sie die anreisenden Besucher bitten, in der Schlange vorgelassen zu werden. Da die Personen, welche ihre Jacke abholen, erst nach einem gewissen Timeout danach fragen werden, ist dieses System hchst inperformant.
Das Erhhen der Anzahl an Kleiderhaken wrde das Problem lediglich hinauszgern, jedoch nicht beheben. Die Lastskalierbarkeit ist folglich sehr schlecht.

=== Rumliche SkalierbarkeitBearbeiten ===
Rumliche Skalierbarkeit weist ein System bzw. Anwendung auf, wenn der Speicherbedarf bei einer wachsenden Anzahl an zu verwaltenden Elementen nicht inakzeptabel hoch ansteigt. Nachdem inakzeptabel ein relativer Begriff ist, spricht man in diesem Zusammenhang in der Regel von akzeptabel, wenn der Speicherbedarf hchstens sub-linear ansteigt. Um das zu erreichen, kann z. B. eine dnnbesetzte Matrix (engl. sparse matrix) bzw. Datenkompression angewendet werden. Nachdem Datenkompression eine gewisse Zeit beansprucht, steht diese jedoch hufig in Widerspruch zur Lastskalierbarkeit.

=== Zeitlich-rumliche SkalierbarkeitBearbeiten ===
Ein System verfgt ber eine zeitlich-rumliche Skalierbarkeit, wenn sich das Erhhen der Anzahl von Objekten die ein System umfasst, nicht erheblich auf dessen Performance auswirkt. Beispielsweise weist eine Suchmaschine mit linearer Komplexitt keine zeitlich-rumliche Skalierbarkeit auf, whrend eine Suchmaschine mit indizierten, bzw. sortierten Daten, z. B. unter Verwendung einer Hashtabelle oder eines balancierten Baums, sehr wohl eine zeitlich-rumliche Skalierbarkeit vorweisen knnte.

=== Strukturelle SkalierbarkeitBearbeiten ===
Strukturelle Skalierbarkeit zeichnet ein System aus, dessen Implementierung das Erhhen der Anzahl von Objekten innerhalb eines selbst definierten Bereichs nicht mageblich behindert.

=== Abhngigkeit zwischen den Arten von SkalierbarkeitBearbeiten ===
Nachdem ein System natrlich mehrere Arten von Skalierbarkeit aufweisen kann, stellt sich die Frage, wie und ob diese miteinander zusammenhngen. Siehe dazu die Tabelle oben.
Die Lastskalierbarkeit eines System wird nicht zwangslufig durch eine schlechte rumliche, oder strukturelle Skalierbarkeit negativ beeinflusst. Systeme mit schlechter rumlicher oder zeitlich-rumlicher Skalierbarkeit haben, aufgrund des Overheads an Speicherverwaltung bzw. des hohen Suchaufwands, mglicherweise auch eine schlechte Lastskalierbarkeit. Systeme mit guter zeitlich-rumlicher Skalierbarkeit haben unter Umstnden eine schlechte Lastskalierbarkeit, wenn z. B. nicht ausreichend parallelisiert wurde.
Der Zusammenhang zwischen struktureller Skalierbarkeit und Lastskalierbarkeit sieht folgendermaen aus. Whrend letztere keine Auswirkungen auf erstere hat, kann das umgekehrt sehr wohl der Fall sein.
Die verschiedenen Arten von Skalierbarkeit sind also nicht zur Gnze unabhngig voneinander.

== SkalierungsfaktorBearbeiten ==

Der Skalierungsfaktor (SpeedUp) beschreibt den tatschlichen Leistungszuwachs einer zustzlichen Ressourcen-Einheit. z. B. kann eine zweite CPU 90 % zustzliche Leistung bringen.
Von einer super-linearen Skalierbarkeit spricht man, wenn der Skalierungsfaktor beim Hinzufgen von Ressourcen grer wird.
Lineare Skalierbarkeit bedeutet, dass der Skalierungsfaktor eines Systems pro hinzugefgter Ressourcen-Einheit gleich bleibt.
Sub-Lineare Skalierbarkeit steht im Gegensatz dazu fr die Abnahme des Skalierungsfaktors beim Hinzufgen von Ressourcen.
Negative Skalierbarkeit wird erreicht, wenn sich die Leistung durch das Hinzufgen von Ressourcen/Rechnern sogar verschlechtert. Mit diesem Problem hat man zu kmpfen, wenn der Verwaltungsaufwand, welcher durch den zustzlichen Rechner entsteht, grer ist als der dadurch erreichte Leistungszuwachs.
Amdahls Gesetz ist ein relativ pessimistisches Modell zur Abschtzung des Skalierungsfaktors. Basierend darauf ist Gustafsons Gesetz eine weitere Methode zur Berechnung dieses Faktors.

== System als SchichtenmodellBearbeiten ==
Um ein System nun mglichst skalierbar aufzubauen hat sich in der Praxis bewhrt, ein solches als Schichtenmodell umzusetzen, da mit diesem Ansatz die einzelnen Schichten logisch voneinander getrennt sind und jede Schicht fr sich skaliert werden kann.
Eine sehr populre Architektur im Web-Bereich ist die 3-Schichten-Architektur. Um dabei eine hohe Skalierbarkeit zu erzielen, ist ein entscheidender Faktor jener, dass jede dieser 3 Schichten gut skaliert.
Whrend die Prsentationsschicht relativ einfach horizontal skaliert werden kann, ist bei der Logikschicht dafr eine speziell dafr ausgelegte Implementierung des Codes erforderlich. Dabei ist zu bercksichtigen, dass ein mglichst groer Anteil der Logik parallelisiert werden kann (siehe Amdahls Gesetz und Gustafsons Gesetz weiter oben). Am interessantesten ist jedoch die horizontale Skalierung der Datenhaltungsschicht, weshalb diesem Thema ein eigener Abschnitt (siehe horizontales Skalieren der Datenhaltungsschicht weiter unten) gewidmet ist.

== Praktische Methoden zur Verbesserung der Skalierbarkeit von WebseitenBearbeiten ==
Verbesserung der Skalierbarkeit von Webseiten kann durch Steigerung der Performance erzielt werden, da ein Server dadurch mehr Clients in der gleichen Zeit bedienen kann.
Martin L. Abbott und Michael T. Fisher haben 50 Regeln aufgestellt, die es in Bezug auf Skalierbarkeit zu beachten gilt. Fr Webseiten sind dabei unter anderem folgende Regeln relevant:

=== Reduzieren von DNS-Lookups und Anzahl von ObjektenBearbeiten ===
Beim Betrachten des Ladens einer Seite in einem beliebigen Browser mit einem Debugging-Tool (z. B. Firebug) fllt auf, dass hnliche groe Elemente unterschiedliche lange Ladezeiten beanspruchen. Bei genauerer Betrachtung erkennt man, dass einige dieser Elemente einen zustzlich DNS-Lookup bentigen. Dieser Vorgang der Adressauflsung kann durch DNS-Caching auf unterschiedlichen Ebenen (z. B. Browser, Betriebssystem, Internet Provider etc.) beschleunigt werden. Um die Anzahl der Lookups zu reduzieren, knnte man nun alle Javascript- und CSS-Dateien zu jeweils einer zusammenfassen und man knnte alle Bilder auf ein groes zusammenfgen und mittels CSS-Sprites nur den gewnschten Bildausschnitt anzeigen. Allgemein kann man folgende Regel dazu aufstellen: Je weniger DNS-Lookups beim Laden einer Seite erforderlich sind, desto besser ist die Performance. Die folgende Tabelle veranschaulicht, wie teuer der DNS-Lookup und der Verbindungsaufbau verhltnismig sind.
Moderne Browser knnen jedoch mehrere Verbindungen gleichzeitig zu einem Server offen halten, um mehrere Objekte parallel herunterzuladen. Laut HTTP/1.1 RFC 2616 sollte das Maximum an gleichzeitigen Verbindungen je Server im Browser auf 2 limitiert werden. Einige Browser ignorieren diese Richtlinie jedoch und verwenden ein Maximum von 6 gleichzeitigen Verbindungen und mehr. Reduziert man auf einer Webseite nun jedoch alle Javascript- und CSS-Dateien, sowie alle Bilder lediglich auf jeweils eine Datei, so entlastet man zwar die anbietenden Server, hebelt jedoch gleichzeitig diesen Mechanismus der parallelen Verbindungen des Browser aus.
Idealerweise nutzt man diese Parallelisierung im Browser zur Gnze aus und hat gleichzeitig mglichst wenige DNS-Lookups. Um das zu erreichen, verteilt man eine Webseite am besten auf mehrere Subdomains (z. B. ruft man Bilder von einer Subdomain auf, whrend man Videos von einer anderen ldt). Durch diese Vorgehensweise lsst sich relativ einfach eine beachtliche Performance-Steigerung erzielen. Es gibt jedoch keine allgemeine Antwort darauf, wie viele Subdomains man verwenden sollte, um die bestmgliche Leistung zu erzielen. Einfache Performance-Tests der zu optimierenden Seite sollten darber jedoch rasch Aufschluss bieten.

=== Horizontales Skalieren der DatenhaltungsschichtBearbeiten ===

==== Skalierung hinsichtlich DatenbankzugriffeBearbeiten ====
Der am schwierigsten zu skalierende Teil eines Systems ist meistens die Datenbank bzw. die Datenhaltungsschicht (s. o.). Der Ursprung dieses Problem kann bis zum Paper A Relational Model of Data for Large Shared Data Banks von Edgar F. Codd zurckverfolgt werden, welches das Konzept eines Relational Database Management System (RDBMS) vorstellt.
Eine Methode um Datenbanken zu skalieren ist es, sich zu Nutze zu machen, dass die meisten Anwendungen und Datenbanken wesentlich mehr Lese- als Schreibzugriffe aufweisen. Ein durchaus realistisches Szenario, das in dem Buch von Martin L. Abbott und Michael T. Fisher beschrieben wird, ist eine Buchreservierungsplattform welche ein Verhltnis zwischen Lese- und Schreibzugriffen von 400:1 aufweist. Diese Art von Systemen knnen relativ einfach skaliert werden, indem mehrere read-only Duplikate dieser Daten angefertigt werden.
Es gibt mehrere Wege um die Kopien dieser Daten zu verteilen abhngig davon, wie aktuell die Daten der Duplikate wirklich sein mssen. Grundstzlich sollte es kein Problem sein, dass diese Daten lediglich alle 3, 30, oder 90 Sekunden synchronisiert werden. Bei dem Szenario der Buchplattform gibt es 1.000.000 Bcher und 10 % davon werden tglich reserviert. Angenommen die Reservierungen sind gleichmig ber den gesamten Tag verteilt, so findet ca. eine Reservierung pro Sekunde (0,86 Sekunden) statt. Die Wahrscheinlichkeit dass zum Zeitpunkt (innerhalb 90 Sekunden) einer Reservierung ein anderer Kunde das gleiche Buch reservieren mchte, betrgt (90/0,86)/100.000 = 0,104 %. Natrlich kann und wird dieser Fall irgendwann eintreffen, doch diesem Problem kann ganz einfach durch eine abschlieende, erneute berprfung der Datenbank entgegentreten werden.
Eine Mglichkeit um diese Methode umzusetzen ist jene, die Daten, z. B. mit einem Key-Value-Store (etwa Redis), zu cachen. Der Cache muss erst nach Ablauf seiner Gltigkeit erneuert werden und entlastet damit die Datenbank enorm. Der einfachste Weg diesen Cache zu implementieren, ist ihn in einer bereits bestehenden Schicht (z. B. der Logikschicht) zu installieren. Fr eine bessere Performance und Skalierbarkeit verwendet man dafr jedoch eine eigene Schicht, bzw. eigene Server, zwischen der Logikschicht und der Datenhaltungsschicht.
Der nchste Schritt ist nun die Datenbank zu replizieren. Die meisten bekannten Datenbanksysteme verfgen bereits ber eine solche Funktion. MySQL bewerkstelligt dies mit dem master-slave-Prinzip, wobei die master-Datenbank die eigentliche Datenbank mit Schreibrechten ist und die slave-Datenbanken die duplizierten read-only Kopien sind. Die master-Datenbank zeichnet smtliche updates, inserts, deletes, etc. im sogenannten Binary-Log auf und die slaves reproduzieren diese. Diese slaves steckt man nun hinter einen Load Balancer (s. u.) um die Last entsprechend zu verteilen.
Diese Art von Skalierung lsst die Anzahl der Transaktionen relativ einfach skalieren. Je mehr Duplikate der Datenbank verwendet werden, desto mehr Transaktionen knnen auch parallel bewltigt werden. In anderen Worten bedeutet das, dass nun beliebig viele User (natrlich abhngig von der Anzahl der Server) gleichzeitig auf unsere Datenbank zugreifen knnen. Diese Methode hilft uns nicht dabei, auch die Daten an sich zu skalieren. Um nun auch beliebig viele Daten in der Datenbank speichern zu knnen, ist ein weiterer Schritt ntig. Dieses Problem wird im nchsten Punkt behandelt.

==== Skalierung hinsichtlich Datenbankeintrge  DenormalisierungBearbeiten ====
Was man hiermit erreichen mchte, ist eine Datenbank auf mehrere Rechner aufzuteilen und dessen Kapazitt beliebig durch weitere Rechner zu erweitern. Dazu muss die Datenbank zu einem gewissen Grad denormalisiert werden. Unter Denormalisierung versteht man die bewusste Rcknahme einer Normalisierung zum Zweck der Verbesserung des Laufzeitverhaltens einer Datenbankanwendung.
Im Zuge der Denormalisierung muss die Datenbank fragmentiert werden.

===== FragmentierungBearbeiten =====
Man unterscheidet horizontale und vertikale Fragmentierung.
Bei der Horizontalen Fragmentierung (Eng. sharding) wird die Gesamtheit aller Datenstze einer Relation auf mehrere Tabellen aufgeteilt. Wenn diese Tabellen auf demselben Server liegen, dann handelt es sich meistens um Partitionierung. Die einzelnen Tabellen knnen aber auch auf unterschiedlichen Servern liegen. So knnen z. B. die Daten fr die Geschfte in den USA auf einem Server in den USA gespeichert werden und die Daten fr die Geschfte mit Europa liegen auf einem Server in Deutschland. Diese Aufteilung wird auch als Regionalisierung bezeichnet.
Horizontale Fragmentierung schafft keine Redundanz der gespeicherten Daten, sondern der Strukturen. Wenn eine Relation gendert werden muss, dann muss nicht nur eine Tabelle gendert werden, sondern es mssen alle Tabellen gendert werden, ber die die Daten aus der betreffenden Relation verteilt sind. Hier besteht die Gefahr von Anomalien in den Datenstrukturen.
Bei der Vertikalen Fragmentierung werden die abhngigen Attribute (nicht-Schlssel-Attribute) einer Tabelle in zwei oder mehrere Gruppen aufgeteilt. Aus jeder Gruppe wird eine eigene Tabelle, die noch um alle Schlssel-Attribute der Ursprungstabelle ergnzt werden. Das kann dann sinnvoll sein, wenn die Attribute einer Relation Datenstze mit einer sehr groen Satzlnge ergeben. Wenn zustzlich noch die Zugriffe meistens nur einige wenige Attribute betreffen, dann kann man die wenigen hufig zugegriffenen Attribute in eine Gruppe zusammenfassen und den Rest in eine zweite Gruppe zusammenfassen. Die hufig auszufhrenden Zugriffe werden dadurch schneller, weil eine geringere Menge an Daten von der Festplatte gelesen werden muss. Die selten auszufhrenden Zugriffe auf die restlichen Attribute werden dadurch nicht schneller, aber auch nicht langsamer.
Ab welcher Satzlnge eine Aufspaltung in mehrere kleinere Tabellen sinnvoll ist, hngt auch von dem Datenbanksystem ab. Viele Datenbanksysteme speichern die Daten in Form von Blcken mit einer Gre von 4 KiB, 8 KiB oder 16 KiB ab. Wenn die durchschnittliche Satzlnge wenig grer als 50 % eines Datenblocks ist, dann bleibt viel Speicherplatz ungenutzt. Wenn die durchschnittliche Satzlnge grer als die verwendete Blockgre ist, dann werden die Datenzugriffe aufwndiger. Wenn BLOBs zusammen mit anderen Attributen in einer Relation vorkommen, ist vertikale Fragmentierung fast immer von Vorteil.

===== PartitionierungBearbeiten =====
Partitionierung ist ein Spezialfall der horizontalen Fragmentierung.
Groe Datenbestnde lassen sich leichter administrieren, wenn die Daten einer Relation in mehrere kleine Teile (=Partitionen) aufgeteilt und diese separat gespeichert werden. Wenn eine Partition einer Tabelle gerade aktualisiert wird, dann knnen andere Partitionen der Tabelle zur selben Zeit reorganisiert werden. Wenn in einer Partition ein Fehler entdeckt wird, dann kann diese einzelne Partition aus einer Datensicherung wiederhergestellt werden, whrend Programme auf die anderen Partitionen weiter zugreifen knnen. Die meisten etablierten Datenbankhersteller bieten Partitionierung an, siehe z. B. Partitionierung bei DB2 und Partitionierung bei MySQL.
Die meisten Datenbanksysteme bieten die Mglichkeit, entweder einzelne Partitionen anzusprechen oder alle Partitionen unter einem einheitlichen Tabellennamen anzusprechen.
Durch Partitionierung knnen die Datenzugriffe beschleunigt werden. Der wesentliche Vorteil ist jedoch die leichtere Administrierbarkeit der gesamten Tabelle.

== Siehe auchBearbeiten ==
OSI-Schichtenmodell

== EinzelnachweiseBearbeiten ==
 Mark D. Hill: What is scalability? In: ACM SIGARCH Computer Architecture News, December 1990, Volume 18 Issue 4, S. 1821, (ISSN 0163-5964). Leticia Duboc, David S. Rosenblum, Tony Wicks: Doctoral symposium: presentations: A framework for modelling and analysis of software systems scalability In: Proceeding of the 28th international conference on Software engineering ICSE '06, May 2006. ISBN 1-59593-375-1, S. 949952
 M. Michael, J.E. Moreira, D. Shiloach, R.W. Wisniewski: Scale-up x Scale-out: A Case Study using Nutch/Lucene. In: Parallel and Distributed Processing Symposium, 2007. IPDPS 2007.. IEEE International. March 26, 2007. Abgerufen am 23. Mai 2012.
 B. Bondi: Characteristics of scalability and their impact on performance. In: Proceedings of the 2nd international workshop on Software and performance (WOSP 00). ACM, New York NY 2000, S. 195203. doi:10.1145/350391.350432
 a b L. M. Abbott, M. T. Fisher: Scalability Rules: 50 principles for scaling Web sites. Addison-Wesley, Indiana 2011, ISBN 978-0-321-75388-5, S. 1234
  Edgar F. Codd: A Relational Model of Data for Large Shared Data Banks. In: Communications of the ACM. ACM Press, New York 13. Juni 1970, 1,5 MB ISSN 0001-0782Kommentar=PDF; 1,5 MB, S. 377387.